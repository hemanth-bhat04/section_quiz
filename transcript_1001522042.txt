So, let's start by understanding the design setup and floor plan. The objective of this module is to introduce the automatic place-and-route flow and focus on the first phase of this process, which involves design setup and floor planning. After completing this module, you will have a general idea of what makes a good floor plan and gain the knowledge to implement a floor plan at both the chip and block levels.

Our agenda includes reviewing the basic design flow, which we have already touched upon. We will discuss what design setup entails, what a floor plan is, and the differences between block-level and chip-level floor plans. Additionally, we will cover the data required for creating a floor plan.
So, these are all various terms that we will encounter. We are listing them here so that you become familiar with them. All of these terms are very important, and you will get to know them by the time you complete the project. Some of them you may already be familiar with, but the rest you will learn along the way.  

Okay, so this is the basic design flow, which we have gone through earlier and understood. As we discussed earlier, there are four major steps in the design of any integrated circuit or chip: RTL design, RTL verification, synthesis, and physical design. We have touched upon some of these steps and gained a top-level understanding of what happens during RTL design and RTL verification. Are we clear?
So, we've worked on logic synthesis and DFT. We also learned about LEC, and now we're at the stage of APR. This is the topic of the next part of the project. The entire project will be completely based on APR. Before we started this project, someone must have already completed the RTL design. They should have performed RTL verification, completed logic synthesis, and inserted DFT. They should have also run LEC and pre-layout STA. At that point, they would have handed off the netlist to us, and that is the state we are in now. We have a netlist to start with.
As we discussed earlier, none of these happen in a modular flow like this or a sequential flow like this. In reality, once the RTL design is completed, only then does RTL verification begin, followed by synthesis, LEC, STA, and APR. However, real designs don't follow this linear approach. Instead, someone might be working on the RTL design while another person starts working on RTL verification. They likely create test plans and use parts of the incomplete RTL code to run RTL verification. As soon as some RTL design is available, synthesis may already be underway, with different team members working on it. Meanwhile, the DFT engineer is already involved in planning what kind of DFT needs to be implemented. When the first netlist becomes available, API work can begin.
Certainly! Here's the corrected version of your text:

---

Already, it starts with the understanding that there will be multiple handoffs. The API team will not work on a single handoff. Typically, a design can have the API running for about twelve to eighteen months. Within that twelve to eighteen-month period, the netlist is likely to be handed off more than ten times. Each time, the netlist is incrementally improved, bugs are fixed, and new features may be added. All these changes keep happening. So, the netlist we have today, which we are going to work on for the project, is not the final netlist. It is intentionally designed this way because if you had a netlist where everything was already fixed, there would be nothing left for you to learn. Most of the learning in the design happens during the initial phases.
Where the layout engineers learn about the design, figure out the right strategies to close it, identify what issues exist, and determine how to modify the existing flow to address those issues—all of these questions get answered in the initial phases. By the time you reach the final stage, there should be little left to do; it becomes more of a "push-button" flow, where you simply press a button, and the layout should be ready. That is the goal they aim for. By that stage, all the necessary learning should have already taken place.  

This is why we are at a point where the current netlist contains most of the intended features, but there are still bugs. For example, some timing constraints might not be met, the SDC (Static Design Constraints) file could be incomplete, the flow itself might not be fully developed, there could be bugs in the flow, or certain settings might be missing.
Here’s the corrected version of your text:

---

So, all those scenarios are still ongoing. When you are working on the project, your job is to identify and address all the issues, making the necessary fixes so that we can move to the next step. Many times, certain fixes may not be possible—for example, the layout team might not be able to resolve every issue. Let’s say there is a timing issue involving a very deep data path; that is something the layout team cannot fix. What the layout team can do is ensure that those cells are placed as close together as possible to reduce path delays as much as possible. Beyond that, the layout team may not be able to do anything else. However, a layout engineer should be able to differentiate between whether the failure is due to the layout itself or another factor.
It's actually the synthesis, so that is the job of the layout engineer. The layout engineer finds all the issues and determines the reasons why something is occurring. Once the reason is identified, they talk to the right people to get it fixed. However, if the issue is related to the layout itself, which is something under the control of the layout engineer, there is no need to involve anyone else. The layout engineer themselves will have to make the necessary fixes and proceed. Okay, so that was about the AC design flow and where we stand now. This is a flat implementation flow, which we've looked at before. Also, in the synthesis...
Here’s the corrected version of your text:

---

So, the top-down flow is a flat implementation flow in the layout design. In a flat implementation flow, like in the top-down approach, everything is created at once. You start with the RTL design, then synthesize it, run pre-layout STA, implement the layout, perform post-layout STA, conduct layout verification, and finally tape out. There is no parallel processing—meaning the design is not broken down into smaller pieces, and different people are not working on separate parts simultaneously. Instead, the entire design is handled as a whole: the entire design is synthesized at once, and the entire design is laid out at once. That’s why this approach is called "flat."
The layout of a flat full chip shows that there is no hierarchy here. These are all the I/Os, which perform the function of transferring data in and out of the chip. What you see here are all the hard macros—maybe this is a PLL—and all the memories. In the middle, you see the logic gates: AND gates, NAND gates, flip-flops, and other components. They are placed within the blue region. The horizontal and vertical lines in green (vertical) and red (horizontal) represent the power nets, which distribute power throughout the chip. Power enters from outside, as indicated by the red lines.
The small rectangles here, right? These are the ones that make a connection from the I/O to the power network. This is where the power connection happens. Power also comes from the outside world, so it enters through this I/O and then gets connected to the power network. Within this power network, you can see something surrounding the area; this is called the **core ring**. The horizontal and vertical lines you see here are called the **core straps**. We'll talk about this again. You can see that, for example, this is the memory, and the horizontal and vertical lines here represent all the connections made to this macro. The VDD and VSS of this macro are connected to the power network in this way.
Here’s the corrected version of your text:

---

So, creating all of this—like placing all the memories, creating all the I/Os, and coming up with the power network—all of this is part of the floor plan. However, placing the standard cells in the middle is not included in this step; that will be handled in the next step. Now, what about the hierarchical implementation flow? In a hierarchical implementation flow, we start with a full RTL design and then proceed to design partitioning. We haven’t really talked about design partitioning yet, so we’ll cover that later. Until now, we’ve been discussing the bottom-up synthesis process, but design partitioning is a key part of that.
It involves partitioning the design at the layout level. The process starts with a full netlist, which is then broken down into smaller chunks for the layout. This partitioning may or may not align with the partitioning done during synthesis. Looking at the picture will make this clearer. Here, you see the layout where all the I/Os are placed around the periphery, and inside the layout, specific areas have been allocated to different parts of the netlist. These areas are labeled as Block 1, Block 2, Block 3, Block 4, Block 5, and Block 6.
All the parts of this netlist—let’s say your design was around sixty million gates—and you pick, for example, ten million gates and place them into Block One. So, all the gates related to that one million gate will be placed here, another million gate here, and so on. I mean, one million gates or ten million gates is just an example, and it doesn’t have to be exactly ten; some blocks might contain five, others ten, and so on. But when you assign a chunk of the netlist to a specific area, you must ensure that the related logic is placed there. You can’t take random logic and assign it to Block One—it has to be related logic. When you group these logics together, they should make sense in terms of not breaking the timing-critical logic across the blocks. Right? It is very important to maintain this coherence.
To the concept we discussed during synthesis, we tried to ensure that when we perform partitioning—whether top-down or bottom-up—the way we break up the hierarchy should be such that we avoid sharing critical-path logic between two different partitions. Sharing critical-path logic between partitions can worsen timing results. The same principle applies here. From the complete netlist, we identify logic that is fairly self-contained and group it into blocks. During synthesis, partitioning was purely logical, but here, it involves physical partitioning. This means not only assigning specific parts of the logic to certain areas but also defining their physical placement.
The shape for it is defined, so Block 1 should look like a square-ish shape, Block 3 looks more rectangular, and there is one L-shaped block. An area has been assigned to each block, and its location on the layout is also determined. When placing the blocks, there should be a reason why Block 1 and Block 2 are sitting next to each other. Perhaps because there are timing-critical paths crossing between them, so signals from Block 1 predominantly go to Block 2. However, the communication between Block 1 and Block 6 is likely not timing-critical, or the amount of signal transfer between them is very low. That’s why these two blocks are probably placed farther apart. So, this design partition is...
This is part of the full chip design, which you will likely work on much later, possibly after the project is complete. This project focuses on implementing one of the blocks—it could be Block 1, Block 3, or any of these blocks. The project is specifically about block implementation, so please be clear about that. Okay, so once each block has been carved out both logically and physically, and a shape has been assigned to it, the block becomes independent. At this point, you can export the shape of the block, and you can also determine where the ports for this block should be located. For example, some ports can be here because they might be communicating with Block 2, so the ports for Block 2 will be positioned there. That way, the connectivity is managed effectively.
Here’s the corrected version of your text:

---

The wire length between Block 1 and Block 2 is reduced. For the communication between Block 1 and Block 3, the ports are placed in the interface so that the wire length is minimized, and so on. The port locations for the blocks, the shape of the blocks, the netlist related to that block, the constraints for the block, and the UPF (User-Defined Power Format) for the block—all of these can be exported. Once that is done, Block 1 looks like an independent design, which will be handled by different engineers. Instead of one person working on such a large chip, now six people can work on it—one block owner per block, plus one top-level engineer, totaling seven people. They all work in parallel since the blocks are much smaller. Instead of handling sixty million gates, now each engineer is handling only ten million gates. As a result, the run times are much better. Once the block engineers complete their work, ...
Here’s the corrected version of your text:

---

When the block is "closed," it means the engineers have completed the entire flow for that block. They have fixed all the timing issues, resolved all the DRC/LVS (Design Rule Check/Layout Versus Schematic) problems, and ensured that everything is closed at that point. These blocks can then be brought back into the overall design. At this stage, you can use a timing model, such as a block extract model or an ATM (Abstract Timing Model), or you can bring back the shape of the block using LEF (Layout Exchange Format). Instead of bringing the entire block back, you only bring back the timing model and the layout model. This reduces the amount of data that needs to be handled at the top level, keeping it manageable.

At the top level, you only need to close the interface timing because everything inside the block is already closed. The timing between Block 1 and Block 2, or between Block 1 and any other block, only needs to be addressed at the interface level. All internal timing within the blocks has already been resolved.
So, the top-level engineer's job is simplified now. Once all the timing issues at the top level and any DRC/LVS issues are resolved, you can export the entire design down to the transistor-level layout. You can then write out a flat GDSII file, which contains the layout information in terms of layers, wells, diffusions, and so on. This file is sent to the foundry for manufacturing. That's about the hierarchical implementation flow. In the hierarchical implementation flow, things happen in parallel. So, we discussed two flows: flat and hierarchical. The setup for these flows involves...
Very similar, though the steps within are different. This is the overview of the APR (Advanced Physical Design) flow. Now that we have covered the basics of APR, we are discussing the individual steps within the APR flow itself. This is a very high-level flow. The first step is **Logical and Physical Data Setup**, followed by **Flow Plan** and **Power Plan**—these are the parts of the current presentation. After that, we need to focus on **Placement**, which involves positioning the standard cells into the standard cell rows. Then, we move on to **Clock Tree Synthesis (CTS)**, which builds the clock tree. We have already talked about CTS, right? So...
Yes, this happens when the clock tree is built. After the clock tree is constructed, we move on to the routing phase, where the wires are added. Until now, the connections between the cells in the layout are, in a sense, imaginary. While the tool has a rough idea of how to route them, the actual wires or metal pieces have not yet been added to the layout. In other words, the metal polygons have not been defined—it’s merely a conceptual or abstract representation of the layout. All those metal polygons are added during the routing phase. Typically, routing consumes a significant amount of resources; you often need larger machines, and the runtime can be quite long. Once the routing is complete, the design becomes much more complex and resource-intensive.
In a sense, if you want to generate a timing report, you open the full chip design and run the `report timing` command. It might take around forty-five minutes to generate the first timing report because the design becomes quite heavy at that point. After that, you'll run DRC (Design Rule Check), LVS (Layout Versus Schematic), and DFM (Design for Manufacturability). We'll discuss DFM later. You have to run all these checks, fix any issues that arise, and only then can you proceed to LECP (Post-Layout Static Timing Analysis). This is part of the APR (Advanced Physical Design) flow.  

Now, let's move on to the first step, which is **Data Setup**. Data Setup involves loading both logical and physical information into the tool.
We know that the API (Application Programming Interface) tool requires many inputs, and there is a specific way of supplying those inputs to the tool. These inputs could be TCL scripts, application variables, or other formats. Some examples of this were already seen when we worked with the Design Compiler tool. For instance, files like `dc_setup.tcl` and `common_setup.tcl` contained setup information. A similar approach is required here as well.  

The tool requests a gateway and, at a minimum, requires logical libraries related to standard cells, I/O cells, and memories. It also needs timing scenarios and other details, which collectively constitute the logical data. In addition to this, API tools also require...
Here’s the corrected version of your text:

---

Until now, we have been handling only the logical part, such as a timing model, a symbol, or a behavioral model. These are all logical views. Until now, we have not touched upon the layout view, right? That is what the physical view refers to—the physical view relates to the layout of the design. Every cell used in the logical library must have a corresponding layout view. The layout tool cannot work without access to the layout data stored in the physical reference library. This data can be in either the M-W (Milky Way) format, which is a slightly older database, or the NDM (Native Design Manager) format, which is the newer one. We’ll look at NDM in a moment, but both formats contain the same information.
That’s just a different database. Supplying the physical data and the logical data into the API tool is called the **data setup**. If you’re working on tools like ICC or even DC, they use a Milkyway database. The Milkyway database comes in two types: the **reference library** and the **design library**.  

The **reference library** is used as a reference, and the data in it is not modified—it’s only used as a reference or linked. For example, the information about an AND gate, as shown here, is stored in the library. The AND gate is a component of the reference library.
That comes from the library vendor, and as a layout engineer, I won’t change it. I’ll simply refer to it. That’s why it is placed in the reference library. The reference library contains, in a Milky Way database, a Unix directory. Under that directory, you navigate into the reference library. Within that directory, you’ll see three subdirectories: `cell`, `frame`, and `lm`. If you go into the `cell` directory and list its contents, you’ll see the names of all the cells. The files under the `cell` directory contain the complete layouts of all the standard cells. These files include all the necessary information, such as details about the cells’ structures and specifications.
The envelope shapes, including the diffusion shapes, contacts, metals, and every layer, are present in the layout that is placed under `cl` or `cell`. From there, you’ll also see the same set of cells, but this time it represents an abstract view. An abstract view means that it is not a complete layout; it contains only a partial layout. This partial layout is required to reduce the amount of data that needs to be loaded. For example, if our layout is at the gate level (and we are not working at the transistor level), then:
The tool does not need to know how the envelope looks. All it needs to know is the shape of, say, an AND gate, where the A pin, B pin, and Y pin are located in the layout, and whether there are any areas in the layout where routing should not occur. This is all the information required for the layout tool. The rest of the information is unnecessary data—if you load it, it will just consume more memory on your machine. To reduce that memory footprint, we use the `from` view. The `from` view is a condensed version of the layout information, and it is generated from the LEF (Layout Exchange Format) file. The LEF file is one of the files handed off by the library team. Then, there is the LM (Library Macro) file.
Under this directory, all your timing libraries are present. However, none of these libraries are stored in their original formats. For example, you cannot directly access or read the `.db` files under `lm`. Instead, the tool stores them in its own internal database format, so you may not be able to read them directly from here. Nevertheless, the contents of the `lm` directory come from the `.db` files, the contents under `frame` come from the `.lef` files, and the contents below `cl` come from the GDS files. All of these libraries were originally provided by the library vendor.

There is a flow that Synopsys offers, which can read all this information and generate a reference library for you. Essentially, a translation process occurs to convert the original library formats into a format usable by the tool. That's an overview of the reference library. Now, let's discuss the design library.
The design library is where you store your layout information. For example, if you're working on a chip and have created a floorplan for it, the floorplan data is stored within the design library. The design library itself is in a specific format called Milky Way. Additionally, the design library has a link to the reference library, which is kept separate because the tool must know the contents of the reference library, and those contents cannot be changed. The only changes allowed are to the contents of the design library. If you look inside the design library, you'll find that it is a unique directory containing two items: one file and one directory. The file, named `lib`, serves as a table of contents, keeping track of all the cells present in the database.
Again, this is for the tools to handle. There's nothing for you to do. You should never go to the design library using Unix commands and try to change anything there. If you do that, your database will get corrupted, and you will lose your data. All the contents of the design library should be handled through the tool commands. To create the design library, there is a command called `create_mw_lib`. In ICC, for example, you can use that command to create the design library. Below that, there is another directory called "cell," where all your saved cells are stored. So, for instance, if I had created a floorplan, I would have saved my design after completing the floorplan.
I referred to it as a "floor plan," and you'll see an entry for it here. After placement, I created another one, which is also present here. I can create multiple floor plans—floor plan 1, 2, 3, 4, 5, 6, or any number of floor plans—and all of them get saved here. These are all binary files, so there is nothing you can do with them using Unix commands apart from listing them. Okay, so that's about the Milky Way. But in the latest tool called ICC2, a different model is used. This model is called NDM (New Data Model). The purpose of the NDM is the same as the Milky Way, but it is designed to be much faster, likely due to advancements in technology. So, ICC2 uses the NDM.
So, here, the same concepts apply: there will be a reference library and a design library. The design library contains multiple blocks, and a block is very similar to a cell in Milky Way. In Milky Way, a cell is equivalent to a block in NDM. For example, Block A might represent a floor plan, Block B might represent placement, and Block C might represent another version of the floor plan. The design library also includes links to the reference library. Reference libraries like `reflib1`, `reflib2`, and `reflib3` (all in NDM format) can be linked into the design library. The design library also contains:
Here’s the corrected version of your text:

---

Technology data—we’ll look at an example of a technology file later. Technology data comes from the technology library, which is provided by the library vendor. This library contains information such as design rules, for example, it might specify that Metal 1 should appear blue with a slanted stipple pattern. It also defines the "look and feel" of the design, including DRC (Design Rule Check) rules. Additionally, the technology data can include details like the height of standard cell rows. All these elements are present in the technology data. Okay, so these are some features of NDM. I think we discussed some of them earlier. Now, regarding the block...
A container for the design data is created when you read the Verilog netlist. For example, the block labeled "Block A" can be created when you load the Verilog netlist into your layout. The block is automatically generated during this process.

A **design library** is a collection of blocks, technology data, and links to technology libraries. A **technology library** contains information about standard cells, macro cells, I/Os, and other blocks used in the current design. 

This reference library may also include references to other blocks. For instance, if you designed a block labeled "Block B" for another chip and want to reuse it as one of the blocks in the current design, then Block B itself can become part of the reference library.
So, the NDM (Netlist Description Model) stores data in mainly two different formats. One format is a single file, where the reference library is stored as a single file. If you look further inside, each cell (e.g., cell one, cell two, cell three, etc.) will have views such as timing, frame, and layout. All of these views for each cell are combined and packaged into one NDM file. On Unix systems, for instance, you'll see just one file that contains information about all the cells. This is how the NDM format is used for the reference library. Additionally, NDM also supports a distributed file system, which is typically used for the design library. In this case, the design library is the top-level directory.
Here’s the corrected version of your text:

---

Under `design/lib` and `lib`, you’ll see multiple directories. These are used to store your design information. The library data is stored in the distributed file system, which serves as the design library. Design libraries typically have an extension of `.nlib`, while reference libraries have an extension of `.ndm`. This is just a convention, and the extension itself has no specific meaning to the tool. You could call both types `.ndm` or both `.nlib`, and it wouldn’t affect the tool’s functionality. However, by convention, we follow this structure: if it’s a reference library, we use the extension `.ndm`, and if it’s a design library, we use the extension `.nlib`.
Okay, so we’ve completed the design setup. Now, let’s understand the floor plan. These are the sub-steps involved in the floor plan:  

1. Place the hard macros.  
2. Place the I/Os (or pins). If it’s a full chip, it’s pin placement; if it’s a block, it’s I/O placement.  
3. Power planning.  

After these three steps are completed, if everything looks good, we can proceed to placement.  

Now, let’s discuss the data required to start the floor plan. Over the next few slides, we’ll cover a lot of new concepts, and many new terms will come up. It might feel a bit overwhelming because...
To hear a lot of things at once, so listen carefully. The data required for starting the floor plan can be categorized under the following groups. To create a good floor plan, you need a lot of information, and all of that information must be studied, processed, and analyzed before you can create the floor plan. It is organized into the following categories:

- **Data coming from technology**: You can obtain information from the architecture, design engineers, or RTL engineers.
- **Information from I/Os**: You need details about the I/O interfaces.
- **Information from IC packages**: You require data related to the packaging specifications.

All of this information, when combined, will help you determine the requirements for creating an effective floor plan.
Floor plan—okay. First, let’s discuss technology-related information. Here, we’re focusing on the technology-related information. The most important file used for technology-related information is called the **tech file**. The tech file is part of your library handoff. It is a text file that contains technology units. Inside the layout tool, there’s a ruler to measure distances. When you draw something, the ruler might show "100," but "100" doesn’t have a unit. The actual unit is defined by the technology library.
It will define the look and feel for various layers, such as how Metal 1 should appear, how the envelope should look, and so on. These are all the various shapes you create on the layout using the layout tool. Each layer will have a different appearance so that you can easily recognize them on the layout. How each layer should look is defined in the technology file. The tech file can also contain layer-specific design rules and inter-layer design rules. All these design rules are only at the metal level because the technology file does not include rules for layers like NOL (N-well), diffusion, or contacts. None of these layers are used in the APR (Advanced Physical Design) tool, as the APR tool operates solely at the gate level. Gate-level design does not require knowledge of...
Because all the invalid layers are present inside the standard cell, which has already been designed. The key point here is that it contains **layer-specific design rules**. Layer-specific rules refer to constraints related to a single layer, such as Metal 1. For example, the minimum width, minimum length, or minimum area for Metal 1 would be considered layer-specific because they apply only to that particular layer.

In contrast, **inter-layer design rules** are the constraints between two layers. For instance, the overlap of Metal 1 with a via involves two layers, and the rule defines the relationship between them. This is an inter-layer design rule.

Additionally, the design rules may also include parameters such as capacitance, resistance, and temperature coefficients for each layer.
Here’s the corrected version of your text:

---

The routing layer will contain the row spacing, which is the height of the standard cell row. Slotting and density rules are additional DRC (Design Rule Check) rules that are part of DFM (Design for Manufacturing). All of this information can be present in a tech file. Okay, let’s see—I’ll try to show an example of a tech file. Uh-huh.
Sure, so can you see the file I’m sharing? Is the text file visible? Alright. Okay, so this is a technology file. As you can see, it’s a text file that we can view. This file specifies things like the dielectric constant and the units, such as the timing unit (nanoseconds) and the length unit (microns).
Right, so all such information is defined here. For example, color names like "green," "bound," and "brown" are referenced as "40," "3," and so on. Stipples, which are patterns of vertical or horizontal lines, are also defined here. These stipple patterns are specified in detail. This section provides information for "ME1," which corresponds to the Metal 1 layer. It includes the layer number, the mask name ("Metal 1"), and various design rules such as default width, minimum area, minimum width, maximum width, and spacing between Metal 1 features. These are all design rules, and specifically, the spacing rule mentioned here is part of the "fact table."
Spacing is not a constant number because the distance between two Metal 1 features varies depending on the width of the Metal 1 itself. The value shown here represents the minimum spacing required. However, the actual spacing increases as the width of the Metal 1 wire becomes larger. Additionally, for longer distances where two Metal 1 features are running parallel, the spacing between them also increases.
Here’s the corrected version of your text:

---

Let’s say this is Metal 1, and this is another Metal 1. The spacing between the two Metal 1 layers depends on the width of this wire itself. That width determines how much space is required between them. If the width increases, the spacing also increases. Additionally, the spacing depends on the length of the wires. If these two metals are running parallel over a longer distance, the spacing requirement also increases.
The spacing rule is not a constant number; it changes depending on the context, and that is what is shown here. This fat table rule specifies the variation, and this appears to represent the X-axis and Y-axis values in the table. Similarly, you’ll see rules for other layers, and this information is presented in a specific format that the tool can interpret. Okay?
That’s an example of a tech file. When you start working on the project, you’ll have access to the tech file. Make sure you open it and go through it. Try to understand what is included in it. Other technology-related information comes from the Liberty file, as Liberty itself is technology-dependent. It contains a lot of information related to the technology, including back-end views. Back-end refers to the layout views, which are also technology-dependent. Physical verification decks rely on the tech file, which contains a subset of design rules. Specifically, it includes design rules related only to the routing layers—such as Metal 1 to Metal 10, depending on what your foundry supports—but the rest of the...
Also, design rules are present in standalone physical verification decks. Before you tape out the chip, it’s not enough to meet design rules just for the metal layers—you have to meet them for every layer. Though the API tool didn’t do anything, let’s consider an example: when an inverter (say, Inverter 1x) was independently designed, the designer who created it would check the design rules for Inverter 1x and ensure everything is clean. However, what happens if Inverter 1x is placed next to a flip-flop? The interaction between them could cause a design rule violation that hasn’t been checked yet. This is difficult to verify because there are thousands of cells, and each cell can sit next to thousands of other cells in the design.
Here’s the corrected version of your text:

---

In many, many thousands of combinations, it’s practically impossible to check all the possibilities. It’s possible that in your layout, some unusual way of placing components could introduce a new design violation. That’s why checking all the layers after the APR (Automatic Place and Route) layout is completed is essential. Without passing DRC (Design Rule Check) and LVS (Layout Versus Schematic) at that stage, you are not allowed to tape out. 

API (Automated Place and Route) tools also perform DRC and LVS checks internally, but their knowledge of DRC rules is primarily related to the metal layers. An API tool is designed for automatic placement and routing, so the routing is entirely done using metal layers. When the tool creates the routing, it is expected to generate routes in such a way that no violations occur.
Since we say it’s all automatic, if a tool has to route something without any DRC violations, you should know the DRC rules. That’s why the DRC rules are included in the tech file. Okay, so then there are parasitic models. PEC stands for Parasitic Extraction. The tool needs access to the parasitic extraction models because otherwise, it cannot determine what amount of resistance (R) and capacitance (C) a wire drawn on the layout represents. All of these are also technology-related. There are two more technology-related files called ITF (Interconnect Technology Format) and TLUPlus. ITF stands for Interconnect Technology Format, and this is the only file that comes to you from the foundry when you are working on the...
A design engineer working on an APR (Advanced Physical Design) tool receives all the technology information from the library vendor. The only file that comes directly from the foundry (fab) is the ITF (Interconnect Technology File). The ITF file defines the cross-section profile of the process. In other words, when you take a chip, cut it, and look at it from the side, you'll see the profile view. That profile view is defined in the ITF file.
A cutaway view, when you look from the side, is what it would look like. So, it could have... Let me try again. So, that could be our N-well, and this could be the diffusion.
There will be a small dielectric layer sitting there, and over that is a polygate. You can't see it well, but let's assume that's what it is. This is the...
So, that may be the silicon dioxide, and you will have a contact. Right? This contact is like this—one contact here and another contact here. Metal 1 is placed here, so that may be Metal 1. I ran out of colors, so I’m using the same pink color, but this is Metal 1. This is the envelope, okay? So, Metal 1 connects to, say, the source. This is the source, right? It’s connected to a gate, and this is connected to a via—or, in this case, it’s called a contact.
The first level of interconnection is called a contact. This contact makes a connection to the source, this contact makes a connection to the gate, and this contact makes a connection to the drain. This is your profile view, and your ITF (Interconnect Technology Format) file defines this profile view. It can specify details such as the thickness of the material, the height of Metal 1, the height of the silicon dioxide, and the height of the diffusion.
Here’s the corrected version of your text:

---

We can also discuss the dielectric constant of silicon dioxide. What’s the dielectric constant of the oxide layer present between the poly and the substrate of your transistor? What is the sheet resistance of Metal 1? All that information is defined in the ITF (Interconnect Technology File). Is that clear? Any questions here? Okay, so that’s the ITF. This ITF information is required by the tools.
Because, as we said, it contains the thickness of the silicon dioxide and the dielectric constant. Both of these pieces of information are required to calculate the parasitic capacitance. It also contains the sheet resistance of Metal 1 and the thickness of Metal 1, which are needed to determine the resistance of the wire. However, the tools cannot read the ITF file directly. In the case of Synopsys tools, the ITF is converted into what is called a TLU+ (Technology Library Update Plus) format. There are tools available that read the ITF file and generate the TLU+ file. The TLU+ models are a set of models that capture advanced process effects and can be used by parasitic extraction tools in Synopsys Place and Route (P&R) flows.
For modeling, it’s a binary file, so we obviously can’t see its contents directly. However, the ITF (Interface Technology File) is a text file and can be viewed. Let me see if I can show you a TLO+ file. Uh-huh.
Okay, so this is the ITF (Interconnect Technology File). As you can see, the dielectric constants are defined here. For example, Metal 7 has a specified thickness, and its sheet resistance is also listed. The dielectric between Metal 7 and Metal 6 has a dielectric constant of a certain value, with a specific thickness. These values define the wire resistances. You can see that everything we discussed is captured in this file. However, again, there is no...
There is something I wanted to mention: I can’t show you the TLUPlus file because it is a binary file, and even if I opened it, there wouldn’t be anything meaningful for you to see. What you need to know now is that the TLUPlus file is generated from the ITF file. Internally, it contains tables that are very similar to the information present in the Liberty file. The tools will read the TLUPlus file and, based on that, extract the R (resistance) and C (capacitance) values for each wire in the layout. That’s about the TLUPlus file.

Now, let’s move on to the design information. Design information can be obtained from the architecture engineers and the RTL engineers. So, what can the architecture...
Design engineers can provide one of the most important things: a data flow diagram. When you work as a physical design engineer, you likely won’t learn the functionality of the chip. This might seem strange, but it’s the reality. You won’t even know what type of chip you are working on or what it does—whether it’s a microprocessor, part of a Cisco server, or something else. For the physical design engineer, the world revolves around meeting timing requirements. As long as you can achieve the timing goals, your job is considered complete. This situation arises for several reasons. One reason is...
Chips are so complex that trying to understand their functionality can be challenging. At the very top level, you might know something general, like whether the chip is intended for a mobile platform. However, gaining a deep understanding of its functionality is rarely possible due to the sheer complexity and the limited time available. Even if the design is from the same company—say, Samsung—you might have access to architecture engineers and RTL design engineers nearby, allowing you to ask questions and gather information. But in other situations, such as when the RTL is designed by Cisco and the layout is done by Broadcom, obtaining that level of insight becomes significantly more difficult.
In such cases, models exist where companies like Cisco will not share all the intricate details of the chip with Broadcom. They will only provide what is necessary. If Broadcom needs additional information, they must explain why it is required, and Cisco will only share it if they deem it important. Given this scenario, it’s not possible to know everything about the design. However, during floorplanning, certain information is essential. Floorplanning is primarily about minimizing wire lengths, so you might want to place key blocks in the floorplan in such a way that critical components are placed close to each other. That kind of information is provided to you through the data flow diagram.
A data flow diagram doesn’t explain the functionality; it only shows how the data flows within your chip. For example, it might indicate that data enters through these two pins, then goes to Block 1. From Block 1, it moves to Block 6, and from Block 6, it goes to Block 2. The interface between Block 1 and Block 3 is critical, so that kind of information is present in the data flow diagram. While this is a simplified representation, it provides enough detail for layout engineers to use and develop the layout. This is the most important information you can get from the architecture design engineers. They can also highlight logic clusters that are critical or high-speed, such as by saying that the interface between these two blocks is very critical.
An additional consideration during floorplanning involves the target die size and aspect ratio. Even before creating the initial netlist, you won’t know exactly how much area the design will occupy. However, the target die size is usually fixed very early in the design process because it directly relates to the cost of the chip. Before the company begins designing, they would have already calculated the production costs and estimated the potential profit based on the chip’s size. Since the production cost and profitability depend heavily on the chip’s dimensions, the target die size is established early on.
They probably already have that information, and sometimes when you receive the first netlist, you might find that the given area isn’t sufficient to fit the netlist—it’s quite possible. In such cases, something might be wrong, so knowing the target die size is important. Gate count is a related term, as it is directly related to the die size. Then, there’s the worst-case voltage drop in the power network, which is related to the power distribution. The power network has resistance, as we saw with core straps, core rings, and other structures when looking at a full-chip layout. These are the wires on the layout that supply current to every transistor. When current passes through these wires, there is a voltage drop due to the resistance (I × R). Whatever voltage drop occurs in the wire...
The voltage drop in the wire is not available to the transistors. So, you might think you’re supplying 1 volt at the pin of the IC, but the transistor inside the IC will not receive 1 volt—it will get much less. This drop is called the **worst-case voltage drop**, and it must be addressed. If the voltage drop is too high, the transistor receives less voltage, which affects its performance. As a result, the gate becomes slower than expected. When architecture engineers decide that the chip is going to operate at 1 GHz, they must account for the worst-case voltage drop. With this much voltage drop for the chosen technology, achieving 1 GHz operation becomes feasible.  

Now, regarding package information
You won’t be able to do everything you wanted because there are constraints along with it. We’ll talk about that when we discuss the package, as the package also determines the voltage drop. If you use a flip-chip package, you’ll experience a smaller voltage drop compared to a wire-bond package. Knowing the package is important, and having access to the block diagram and pin diagram is helpful. It’s better to review these documents before jumping into floor planning, as the type of package determines how you approach the floor plan. We’ll see an example later. The way you lay out the design for a wire-bond package is different from the way you do it for a flip-chip package. That’s about the design information.
You can obtain some design information from the architecture design engineers. Additionally, the RTL designers can provide you with pin naming conventions. Generally, RTL engineers follow specific pin naming conventions. For example, a signal that exits Block 1 and connects to Block 2 might be named as "Block1\_Block2\_something." This naming convention helps identify that the signal is intended for Block 2. Such information can sometimes be useful for your floorplanning efforts. Regarding the netlist and gate count, this information is typically available from the RTL designers. Then, there are clock domains: you need to know how many clocks are in your design, which ones are synchronous, and which ones are asynchronous.
What are their frequencies, or at least the expected frequencies? Then, consider the voltage domains: How many voltage domains are there in your design? Which ones are shut down, and which ones are always on? All of this information can be obtained from here. Next, there’s DFT (Design for Test) information: What kind of DFT implementation has been done? Do we have scan chains? Are there P/Bs (Parallel/Block tests)? Is there L-BIST (Logic Built-In Self-Test)? What types of DFT have been implemented in this design?  

When you implement DFT, some additional pins are introduced. For example, scan-in, scan-out, and scan-enable pins are added due to DFT. There could be many more pins like this, each bringing in its own set of requirements. However, typically, the DFT team will not get...
Pins just like that—you can’t have a dedicated pin for DFT (Design for Test) because having a pin on the package comes at a cost. Allocating a pin solely for testing purposes isn’t financially viable, as no one is willing to spend extra money to make the package more complex. If you have more pins, it means the package needs to accommodate more pins, and each pin adds to the overall cost. To reduce costs, DFT pins are typically shared. When you’re in DFT mode, your functional pins act as DFT pins. Therefore, you’ll need to know which pins are shared between DFT and functional components because those pins will have multiple timing characteristics. DFT has one set of timing requirements, while the functional part has a completely different set. Understanding this is important.

Next, let’s discuss macro usage guidelines. Macros are components like memories or PLLs (Phase-Locked Loops), and they
Here’s the corrected version of your text:

---

They come with their own usage guidelines. Whoever handed out the memory or all these macros to you will usually provide usage guidelines along with them. PLLs (Phase-Locked Loops) are particularly notorious because they are very sensitive elements and come with a lot of restrictions. For example, they might specify that you cannot place anything within fifty microns of the edge of the PLL. They might also state that you cannot route over the PLL with any metal. Additionally, they might require that the power supply to the PLL (e.g., VDD) should not be connected to the digital supply of the rest of the chip. This means that even if the rest of the chip is running on VDD, you should not connect the PLL’s supply to the same VDD because that VDD is very noisy. If the noise couples into the PLL, it can generate clock jitter, which is undesirable.
Or, two or three cycles later, it will increase the jitter. This will make your timing closure more complicated because the jitter reduces the amount of time available in the clock period. They might have guidelines on how you should connect the power to the PLL, and all of that is included in your macro usage guidelines. So, you should read these guidelines before jumping into the floorplan and trying to implement anything.  

Pin connection guidelines are also important. Sometimes, these macros will come with more than one VDD or VSS. For example, they might have ten VDD pins and ten VSS pins, but the guidelines might specify that you should connect at least five of them. These extra pins are created to make your design easier, but it may not always be possible to connect all ten due to layout constraints. However, connecting at least five of them is usually sufficient.
So that gives you flexibility, which is why they will provide more than ten pins—more than the required number of pins—but they expect you to make at least a certain number of connections. All of these details are present in the guidelines. OTC stands for "Over-the-Cell" routing restrictions. It specifies what restrictions apply to routing over the cell. For example, we saw that the PLL internally uses Metal 1 to Metal 5, so those five metals are obviously unavailable for use at the top level. However, you can use Metal 6 and above. The guidelines might demand, for instance, "Don’t route Metal 6 over it," or "Route Metal 7 to avoid crosstalk." Additionally, there are SKA (Standard Key Attributes) guidelines for digital hard macros. These hard macros are more complex cells.
Oh, like maybe a SerDes (Serializer/Deserializer). SerDes stands for Serializer-Deserializer, and these cells are designed to handle only data without a clock input. Transmitting the clock is very difficult, especially in chip-to-chip communication. The biggest challenge is that you have to transmit both data and the clock, but the clock frequency is at least twice the data frequency. For example, if you transmit a 1 GHz clock, the maximum data frequency is limited to half of that, which is 500 MHz, because you can change the data only at the rising edge of the clock. So, what if we avoid transmitting the clock? If we don’t transmit the clock, we can potentially transmit the data at double the speed.
Transmit only the data. Now, my data can toggle at 1 GHz. However, the problem with this approach is that without a clock, synchronous circuits won’t work because they rely on the clock as a reference. That’s where SerDes comes in. Internally, the SerDes guesses where the clock is because it knows that whenever a data transition occurs, that’s where the clock transition should have happened. Let’s see if I can illustrate that. Suppose the data makes a transition here. If the data transition happens like this, it means the clock must have made a transition at the same point.
Right. Data can only change at the rising edge of the clock because this data is coming from a flip-flop. SerDes uses this principle: when it detects a data transition, it assumes that the corresponding clock transition should occur at that point. To achieve this, SerDes runs an internal oscillator-like mechanism that can be tuned. Based on this, it extracts the clock on its own. This is how SerDes works.  

Now, regarding the timing requirements for a digital hard macro like SerDes, these requirements are extremely complex. The timing requirements for SerDes cannot be fully captured in a Liberty file because Liberty files were originally designed to capture timing information for simple standard cells or gates. This is one of the reasons...
Which we used to work on had a strange requirement. Say that was our service, and inside this service, it used to send a clock out. That clock would then be captured by a flip-flop in another block, and from there, the clock was returned. Internally, that clock came back inside to the service. When this happened, the entire round-trip delay—the clock going out and coming back—shouldn’t exceed, say, five hundred microseconds.
So, that was the requirement. We can see that this cannot be captured in Liberty because Liberty has no constructs to explain it. Since this cannot be captured in Liberty, it becomes a timing guideline, which is documented in the usage document supplied with the IP you purchased. All such timing requirements are typically handled by the layout engineers. You may end up having to write a script to compute the delay, extract the delay from your layout, and then manually check it against the guidelines. That was an example of STA (Static Timing Analysis) guidelines for digital hard macros. Now, let’s discuss testing connections. We’ve already talked about this earlier.
