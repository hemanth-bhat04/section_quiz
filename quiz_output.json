{
  "chapters": {
    "Introduction to Data Science": {
      "sections": {
        "introduction to data science": {
          "keywords": [],
          "questions": {
            "content": "Here are 3 multiple-choice questions for degree-level Computer Science students based on the provided keywords:\n\nL1 - Individual-topic question:\nWhat is the purpose of a compiler in a computer system?\nA) To translate high-level code into machine code\nB) To manage system memory allocation\nC) To handle user input/output operations\nD) To optimize code for better performance\n\nKeywords: compiler\n\nL2 - Combination-topic question:\nWhich of the following is NOT a key component of the TCP/IP model?\nA) Transport\nB) Network\nC) Application\nD) Session\n\nKeywords: TCP, IP, model\n\nL3 - Individual-topic question:\nWhat is the main purpose of a firewall in a network security system?\nA) To encrypt data packets for secure transmission\nB) To monitor and control incoming and outgoing network traffic\nC) To authenticate user identities before granting access\nD) To detect and remove malware from the system\n\nKeywords: firewall, network, security\n\nL2 - Combination-topic question:\nWhat is the difference between a stack and a queue in data structures?\nA) Stack follows LIFO (Last In, First Out) while queue follows FIFO (First In, First Out)\nB) Stack is implemented using arrays while queue is implemented using linked lists\nC) Stack is used for breadth-first traversal while queue is used for depth-first traversal\nD) Stack is thread-safe while queue is not\n\nKeywords: stack, queue, data structure, LIFO, FIFO"
          }
        },
        "test": {
          "keywords": [
            "computer science",
            "data science",
            "making process computer science data scientists"
          ],
          "questions": {
            "content": "### Multiple Choice Questions\n\n#### Question 1\nWhat is the primary focus of Computer Science?\nA) The study of living organisms and their interactions with the environment\nB) The scientific study of data and its application to real-world problems\nC) The design, development, and use of computer systems and software\nD) The study of the Earth's physical and natural phenomena\nL1, Individual-topic (Computer Science)\n\n#### Question 2\nIn the context of data science, which of the following is NOT a primary activity?\nA) Data collection\nB) Data cleaning\nC) Data visualization\nD) Data interpretation\nL2, Individual-topic (Data Science)\n\n#### Question 3\nWhich of the following best describes the making process in the context of computer science and data science?\nA) It involves the creation of algorithms and data structures\nB) It encompasses the entire lifecycle of turning raw data into actionable insights\nC) It refers to the physical manufacturing of computer hardware components\nD) It is the process of translating human language into machine language\nL3, Combination-topic (Computer Science, Data Science, Making Process)\n\n#### Question 4\nHow are Computer Science and Data Science related?\nA) Computer Science is a subset of Data Science\nB) They are completely independent fields with no overlap\nC) Data Science is a subset of Computer Science\nD) They are two different fields that occasionally intersect\nL2, Combination-topic (Computer Science, Data Science)\n\n#### Question 5\nWhat is a critical skill for a data scientist in the making process?\nA) Ability to code in multiple programming languages\nB) Knowledge of only one type of database system\nC) Ignorance of statistical analysis\nD) Inability to use data visualization tools\nL1, Combination-topic (Data Science, Making Process)\n\n#### Question 6\nIn the context of the making process, what does the term \"computer science\" primarily refer to?\nA) The study of the natural world and the physical universe\nB) The study of the principles and practice of computation and its application\nC) The study of the human mind and its processes\nD) The study of the Earth's atmosphere\nL1, Combination-topic (Computer Science, Making Process)\n\n#### Analysis:\n- Question 1 is an individual-topic question focusing on Computer Science.\n- Question 2, 4, and 6 are combination-topic questions, incorporating multiple keywords.\n- Question 3 and 5 are combination-topic questions, but also touch on the making process in computer science and data science."
          }
        },
        "The Data Science Process": {
          "keywords": [
            "computer science",
            "data science",
            "making process computer science data scientists"
          ],
          "questions": {
            "content": "### Multiple-Choice Questions\n\n#### Question 1: [L1] What is the primary focus of Data Science?\nA. Designing computer systems and software\nB. Analyzing and interpreting complex digital data\nC. Teaching computer science fundamentals\nD. Developing algorithms for data processing\n\n**Answer: B**\n\n- **Explanation:** Data Science primarily involves collecting, analyzing, and interpreting complex digital data to extract insights and knowledge. While computer science is a related field, its focus is broader, including system design and algorithm development, which are not the primary goals of data science.\n\n#### Question 2: [L2] Which of the following is NOT a primary task in the making process of a computer scientist?\nA. Writing code\nB. Data analysis\nC. Designing algorithms\nD. Marketing research\n\n**Answer: D**\n\n- **Explanation:** While computer scientists may engage in various activities, marketing research is not a primary task in the making process of a computer scientist. Their main focus is on designing and analyzing algorithms, writing code, and solving computational problems.\n\n#### Question 3: [L3] Combination Topic Question: How do Computer Science and Data Science interrelate in the context of developing a predictive model?\nA. Computer Science is used to design the predictive model, while Data Science is used to interpret the data.\nB. Both fields work independently, with Computer Science focusing on the technical implementation and Data Science on the analysis.\nC. Data Science is a subset of Computer Science, and both are used interchangeably in model development.\nD. Computer Science and Data Science are entirely separate disciplines with no direct interaction in model development.\n\n**Answer: B**\n\n- **Explanation:** In the context of developing a predictive model, Computer Science and Data Science complement each other. Computer Science provides the technical foundation for building the model and its infrastructure, while Data Science involves analyzing and interpreting data to build predictive models and insights. They are distinct but closely related fields that often collaborate in project development.\n\n### Analysis\n\n- Question 1 is an Individual-Topic question focused on \"Data Science.\"\n- Question 2 is an Individual-Topic question focused on the \"Making process of a computer scientist.\"\n- Question 3 is a Combination-Topic question involving \"Computer Science\" and \"Data Science.\""
          }
        }
      },
      "chapter_questions": {
        "keywords": [
          "computer science",
          "data science",
          "making process computer science data scientists"
        ],
        "questions": {
          "content": "### Multiple Choice Questions\n\n#### Question 1: What is the primary focus of Computer Science?\n- A) The study of the Earth's atmosphere and its phenomena\n- B) The study of the physical and mathematical sciences\n- C) The scientific and practical approach to computation and its applications\n- D) The study of living organisms and their interactions with the environment\n- L1, Individual-topic\n\n#### Question 2: Which of the following is NOT a core aspect of Data Science?\n- A) Data Collection\n- B) Data Analysis\n- C) Data Visualization\n- D) Quantum Physics\n- L1, Individual-topic\n\n#### Question 3: In the making process of becoming a computer scientist, which of the following is NOT a typical step?\n- A) Attending university courses in Computer Science\n- B) Gaining practical experience through internships or projects\n- C) Participating in research projects\n- D) Learning to play a musical instrument\n- L1, Individual-topic\n\n#### Question 4: Which of the following best describes the role of a Data Scientist?\n- A) Designing computer systems and software\n- B) Analyzing and interpreting complex data to help businesses make informed decisions\n- C) Teaching computer science in schools\n- D) Performing surgery on humans\n- L2, Combination-topic (Computer Science, Data Science)\n\n#### Question 5: In the context of the making process for becoming a data scientist, which of the following is considered a crucial step?\n- A) Obtaining a degree in Philosophy\n- B) Mastering advanced statistical techniques\n- C) Developing a strong foundation in programming languages\n- D) Learning to play professional sports\n- L2, Combination-topic (Data Science, making process computer science data scientists)\n\n### Keywords Used:\n- Question 1: Computer Science\n- Question 2: Data Science\n- Question 3: making process computer science\n- Question 4: Computer Science, Data Science\n- Question 5: Data Science, making process computer science data scientists\n\n*Note: All questions are tagged with the appropriate difficulty level, and the type (individual-topic or combination-topic) is indicated for each question.*"
        }
      }
    },
    "Computer vision": {
      "sections": {
        "Image Processing": {
          "keywords": [
            "singular value decomposition",
            "filtering facebook",
            "image processing",
            "computer vision",
            "information retrieval",
            "linear algebra",
            "image processing pictures computer vision cameras photoshop illumination slides signature probably theory difference equation singular value decomposition mathematic equations information retrieval linear algebra",
            "image processing pictures computer vision cameras photoshop illumination slides signature probably theory difference equation",
            "mathematic equations information retrieval linear algebra",
            "people",
            "tight relationship branches instagram matrix theory hair",
            "eyes",
            "filtering"
          ],
          "questions": {
            "content": "### Individual-topic Questions\n\n**Q1: What is the primary purpose of Singular Value Decomposition (SVD) in the context of linear algebra?**\n\nL1\n\nA) To filter images in real-time\nB) To process images for computer vision tasks\nC) To decompose a matrix into three matrices, providing insights into its rank, range, and null space\nD) To retrieve information from a dataset\n\n**Q2: In the context of image processing, what is the role of illumination in modifying the appearance of an image?**\n\nL1\n\nA) It determines the color and brightness of the image\nB) It is used to filter images in real-time\nC) It is a branch of computer vision focusing on hair and eyes\nD) It is a method for retrieving information from a dataset\n\n**Q3: Which of the following is NOT a common application of information retrieval in computer science?**\n\nL2\n\nA) Searching for relevant documents within a database\nB) Filtering images on social media platforms like Instagram\nC) Decomposing a matrix into its singular values\nD) Processing images for computer vision tasks\n\n### Combination-topic Questions\n\n**Q4: How does Singular Value Decomposition (SVD) relate to image processing and linear algebra?**\n\nL2\n\nA) SVD is a method used in image processing to enhance the quality of images by reducing noise.\nB) SVD is a linear algebra technique that can be applied to improve image compression algorithms.\nC) SVD is a fundamental tool in linear algebra with no direct application in image processing.\nD) SVD is a technique used in both linear algebra and image processing for matrix factorization.\n\n**Q5: Consider a scenario where you want to analyze people's facial features using computer vision techniques. Which combination of tools and theories would be most relevant?**\n\nL3\n\nA) Image processing techniques, matrix theory, and information retrieval algorithms\nB) Filtering techniques, computer vision, and hair and eyes analysis\nC) Singular Value Decomposition, information retrieval, and linear algebra\nD) Photoshop, illumination theory, and signature analysis\n\n**Q6: In the context of computer vision, how does the use of cameras and slides differ in terms of capturing and processing images?**\n\nL2\n\nA) Cameras capture live images, while slides display pre-processed images.\nB) Slides are used to enhance the quality of images captured by cameras.\nC) Cameras are used for real-time image processing, whereas slides are used for static image analysis.\nD) There is no significant difference between cameras and slides in computer vision applications.\n\n### Answer Key\n\n- Q1: C\n- Q2: A\n- Q3: B\n- Q4: D\n- Q5: A\n- Q6: C\n\n### Keyword Analysis\n\n- Q1, Q4: Singular Value Decomposition, Linear Algebra, Information Retrieval\n- Q2, Q6: Image Processing, Illumination\n- Q3: Information Retrieval\n- Q5: Computer Vision, Matrix Theory, Image Processing"
          }
        },
        "Edge detection": {
          "keywords": [
            "median",
            "frequency domain",
            "convolutional filter",
            "roberts step number original image differentiation",
            "double edges sobel gradient bell kenny median value maximum suppression",
            "canny edge interpolation median numbers",
            "roberts step number original",
            "image",
            "differentiation",
            "gradient",
            "edge",
            "interpolation"
          ],
          "questions": {
            "content": "### Individual-topic Questions\n\n**Q1: What is the purpose of a convolutional filter in image processing?**\n\nA) To enhance the contrast of an image.\nB) To detect edges in an image by finding the gradient.\nC) To calculate the median value of a set of numbers.\nD) To interpolate missing values in an image.\n\n**Q2: In the context of edge detection, which of the following is NOT a common method?**\n\nA) Roberts Cross Method\nB) Sobel Edge Detection\nC) Canny Edge Detection\nD) Median Filtering\n\n**Q3: The median value in a sorted list of numbers is the:** (L1)\n\nA) The middle value when the number of elements is odd.\nB) The average of the two middle values when the number of elements is even.\nC) The highest value in the list.\nD) The lowest value in the list.\n\n---\n\n### Combination-topic Questions\n\n**Q4: In the Roberts Cross Method for edge detection, what is the first step before applying the differentiation?** (L2)\n\nA) Applying a convolutional filter.\nB) Interpolating missing values in the image.\nC) Calculating the median value of the image.\nD) Suppressing the maximum gradient values.\n\n**Q5: Which of the following edge detection methods uses both horizontal and vertical gradients to determine the edge strength and direction?** (L2)\n\nA) Roberts Cross Method\nB) Sobel Edge Detection\nC) Canny Edge Detection\nD) Median Filtering\n\n**Q6: In the context of edge detection, which method involves the suppression of the maximum gradient values to reduce noise and improve edge definition?** (L3)\n\nA) Roberts Cross Method\nB) Sobel Edge Detection\nC) Canny Edge Detection with the use of a hysteresis thresholding technique.\nD) Median Filtering\n\n---\n\n### Key Information:\n\n- **Q1, Q2, Q4, Q5, Q6** are combination-topic questions.\n- **Q3** is an individual-topic question.\n- **Q3** is based on the keyword \"median\"."
          }
        },
        "Image Classification using Keras": {
          "keywords": [
            "layer",
            "highest prediction models",
            "test data",
            "neural network",
            "data type",
            "classification models loss position index resize image",
            "models loss position index resize image",
            "images cell data",
            "probabilities conversion deer sale",
            "classification",
            "highest",
            "prediction",
            "models",
            "image",
            "pooling",
            "training",
            "convolution",
            "pixel"
          ],
          "questions": {
            "content": "### MCQs\n\n1. L1: What is the purpose of the \"pooling\" operation in a neural network?\n   a) To increase the spatial dimensions of the feature maps\n   b) To reduce the dimensionality of the feature maps and extract dominant features\n   c) To enhance the resolution of the input images\n   d) To improve the training speed of the model\n\n2. L2: In the context of neural networks, what does \"highest prediction models\" refer to?\n   a) The models that have the highest number of layers\n   b) The models that produce the highest accuracy on a given dataset\n   c) The models that employ the highest computational resources\n   d) The models that are situated at the highest levels of an organizational hierarchy\n\n3. L3: During the training phase of a classification model, what is the role of \"test data\"?\n   a) To evaluate the model's performance and fine-tune its parameters\n   b) To increase the complexity of the model\n   c) To augment the training dataset\n   d) To replace the training data if the training dataset is insufficient\n\n### Explanation\n\n- **MCQ 1** is an individual-topic question focusing on the concept of \"pooling\" in neural networks. The correct answer is b) To reduce the dimensionality of the feature maps and extract dominant features. Pooling is a crucial operation in convolutional neural networks (CNNs) that helps in reducing the spatial size of the representation, thereby reducing the number of parameters and computation in the network, and also helping to capture the most important features.\n\n- **MCQ 2** is a combination-topic question combining \"highest prediction models\" and \"neural networks\". This question is designed to test the understanding of how the term \"highest prediction models\" is interpreted in the context of neural networks, with the correct answer being b) The models that produce the highest accuracy on a given dataset. This reflects the common use of neural networks for tasks where the goal is to achieve the highest predictive performance.\n\n- **MCQ 3** is also a combination-topic question, focusing on \"test data\" and \"classification model training\". This question aims to understand the role of test data in the training phase of a classification model, with the correct answer being a) To evaluate the model's performance and fine-tune its parameters. Test data is crucial for evaluating model performance and making adjustments to improve the model's accuracy without risking overfitting on the training data."
          }
        },
        "Convolutional Neural Networks": {
          "keywords": [
            "image",
            "pixel",
            "image pixel",
            "convolutional neural network",
            "slash letters pixel diagonals",
            "letters pixel diagonals",
            "convolutional layer",
            "simple world gradient descent",
            "fully connected layer",
            "second filter highest score",
            "neural network",
            "forward slash",
            "gradient descent",
            "artificial intelligence",
            "random numbers",
            "machine learning",
            "image pixel convolutional neural network",
            "convolution convolutional layer simple world gradient descent",
            "fully connected layer gradient classifier resolution neural networks",
            "gradient classifier resolution neural networks"
          ],
          "questions": {
            "content": "Here are 3 multiple-choice questions (MCQs) for degree-level Computer Science students based on the provided keywords:\n\nL1 (Individual-topic)\nWhat is a pixel in the context of digital images?\nA) A single dot of color on a display\nB) A mathematical function used in image processing\nC) A layer in a convolutional neural network\nD) A type of neural network architecture\nCorrect Answer: A) A single dot of color on a display\nKeywords: image, image pixel\n\nL2 (Combination-topic)\nHow does a convolutional layer in a convolutional neural network process image data?\nA) By applying a mathematical operation across the entire image\nB) By analyzing random numbers generated from the image pixels\nC) By sliding a filter over the image and computing dot products\nD) By connecting all pixels in a fully connected layer\nCorrect Answer: C) By sliding a filter over the image and computing dot products\nKeywords: image pixel, convolutional neural network, convolutional layer\n\nL3 (Individual-topic)\nWhat is gradient descent used for in training neural networks?\nA) Initializing the weights of the network randomly\nB) Determining the second filter with the highest score\nC) Optimizing the network's performance by minimizing the loss function\nD) Selecting the best resolution for neural networks\nCorrect Answer: C) Optimizing the network's performance by minimizing the loss function\nKeywords: simple world gradient descent, neural network, gradient descent"
          }
        }
      },
      "chapter_questions": {
        "keywords": [
          "singular value decomposition",
          "filtering facebook",
          "image processing",
          "computer vision",
          "information retrieval",
          "linear algebra",
          "image processing pictures computer vision cameras photoshop illumination slides signature probably theory difference equation singular value decomposition mathematic equations information retrieval linear algebra",
          "image processing pictures computer vision cameras photoshop illumination slides signature probably theory difference equation",
          "mathematic equations information retrieval linear algebra",
          "people",
          "tight relationship branches instagram matrix theory hair",
          "eyes",
          "filtering",
          "median",
          "frequency domain",
          "convolutional filter",
          "roberts step number original image differentiation",
          "double edges sobel gradient bell kenny median value maximum suppression",
          "canny edge interpolation median numbers",
          "roberts step number original",
          "image",
          "differentiation",
          "gradient",
          "edge",
          "interpolation",
          "layer",
          "highest prediction models",
          "test data",
          "neural network",
          "data type",
          "classification models loss position index resize image",
          "models loss position index resize image",
          "images cell data",
          "probabilities conversion deer sale",
          "classification",
          "highest",
          "prediction",
          "models",
          "pooling",
          "training",
          "convolution",
          "pixel",
          "image pixel",
          "convolutional neural network",
          "slash letters pixel diagonals",
          "letters pixel diagonals",
          "convolutional layer",
          "simple world gradient descent",
          "fully connected layer",
          "second filter highest score",
          "forward slash",
          "gradient descent",
          "artificial intelligence",
          "random numbers",
          "machine learning",
          "image pixel convolutional neural network",
          "convolution convolutional layer simple world gradient descent",
          "fully connected layer gradient classifier resolution neural networks",
          "gradient classifier resolution neural networks"
        ],
        "questions": {
          "content": "Here are 5 multiple-choice questions for degree-level Computer Science students, based on the provided keywords:\n\nL1: Which of the following is a technique used in image processing to reduce noise and enhance edges in an image?\nA) Singular Value Decomposition\nB) Filtering Facebook\nC) Median Filtering\nD) Information Retrieval\nCorrect Answer: C) Median Filtering\nKeywords: image processing, filtering, median\n\nL2: Which of the following is NOT a branch of computer vision?\nA) Image Processing\nB) Information Retrieval\nC) Machine Learning\nD) Hair and Eyes Analysis\nCorrect Answer: D) Hair and Eyes Analysis\nKeywords: computer vision, branches\n\nL3: In the context of linear algebra, which of the following is a method used to factorize a matrix?\nA) Image Processing\nB) Singular Value Decomposition\nC) Photoshop\nD) Convolutional Filter\nCorrect Answer: B) Singular Value Decomposition\nKeywords: linear algebra, singular value decomposition\n\nL1: Which of the following is an algorithm used for edge detection in digital images?\nA) Roberts Step\nB) Data Type\nC) Gradient Descent\nD) Canny Edge Detection\nCorrect Answer: D) Canny Edge Detection\nKeywords: image processing, edge, gradient\n\nL2: Which of the following is a technique used in convolutional neural networks to reduce the spatial dimensions of the input volume?\nA) Pooling\nB) Fully Connected Layer\nC) Gradient Descent\nD) Forward Slash\nCorrect Answer: A) Pooling\nKeywords: convolutional neural network, pooling\n\nIndividual-topic questions: Questions 1, 4\nCombination-topic questions: Questions 2, 3, 5"
        }
      }
    },
    "Machine learning algorithms": {
      "sections": {
        "Naive Bayes": {
          "keywords": [
            "classification naive bayes",
            "naive bayes",
            "random variables",
            "bayesian methods",
            "initial guess training data",
            "machine learning",
            "total number weight classification",
            "total number weight",
            "bayes rule",
            "finite set",
            "data set",
            "probabilistic model family random variables",
            "prediction naive bayes initial guess training data",
            "dear friend histograms machine learning data",
            "probabilistic model family",
            "dear friend histograms",
            "classification",
            "bayes",
            "prediction",
            "data"
          ],
          "questions": null
        },
        "Support Vector Machines": {
          "keywords": [
            "support vector machines",
            "vector machines",
            "vector prediction constraint",
            "optimization problem",
            "lagrange multipliers",
            "vector observations misclassifications",
            "green dots outliers",
            "maximum margin",
            "classifier hyperplane soft margin",
            "feature vector",
            "decision boundary",
            "binary classification",
            "machine learning",
            "vector prediction constraint optimization problem decision",
            "vector machines lagrange multipliers kernel",
            "dimensional space data point weight vector observations misclassifications",
            "dimensional axis channel member polynomial kernel",
            "dual variables",
            "alphas hyperplanes",
            "closest point"
          ],
          "questions": null
        },
        "Linear Regression": {
          "keywords": [
            "statistics",
            "independent variable",
            "linear regression",
            "null hypothesis",
            "test data",
            "average value linear relationship",
            "data set",
            "linear relationship",
            "values software packages average value",
            "null hypothesis squares error term interpretation data",
            "squares error term interpretation data",
            "independent variable average value linear relationship",
            "variation actual values",
            "critical values",
            "positive relationship",
            "value goodness",
            "regressors",
            "correlation",
            "ttest",
            "software"
          ],
          "questions": {
            "content": "### Question 1: L1 - Individual-topic\nWhich of the following is an independent variable in a linear regression model?\n\nA) Dependent variable\nB) Independent variable\nC) Null hypothesis\nD) Correlation\n\n**Keywords used:** independent variable\n\n### Question 2: L2 - Individual-topic\nIn the context of linear regression, what does the term \"squares error term interpretation data\" refer to?\n\nA) The process of interpreting the error term in a linear regression model\nB) A specific type of data used in regression analysis\nC) A method for interpreting data based on the squared errors\nD) A term used to describe the relationship between the error term and the data\n\n**Keywords used:** squares error term interpretation data\n\n### Question 3: L3 - Combination-topic\nIn a statistical test, what is the role of the null hypothesis?\n\nA) To represent the expected outcome if there is no relationship between variables\nB) To describe the alternative explanation for the observed data\nC) To represent the actual data being tested\nD) To determine the significance level of the test\n\n**Keywords used:** null hypothesis, test data"
          }
        },
        "Logistic Regression": {
          "keywords": [
            "logistic regression",
            "data set",
            "simple linear regression",
            "birth weight data",
            "age weight linearity",
            "independent variable",
            "logistic function",
            "linear regression",
            "odds ratio menstrual period predictor slope coefficient logistic regression weight exponential function equation association",
            "value percent vertical axis",
            "observations data",
            "age",
            "weight",
            "linearity",
            "predictions",
            "interpretation",
            "correlation"
          ],
          "questions": null
        },
        "Hierarchical clustering": {
          "keywords": [
            "cluster number dendrograms",
            "heat maps sample number similarity clusters",
            "number dendrograms",
            "closest point colors",
            "heat maps sample number similarity",
            "clusters",
            "quest gene manhattan distance square root"
          ],
          "questions": null
        },
        "Decision Trees": {
          "keywords": [
            "decision tree",
            "decision tree heart disease chest pain patient leaf nodes",
            "numeric data blood circulation yesno question gini impurity separation cutoff weight news color choices",
            "news color choices",
            "total number",
            "heart disease chest pain patient leaf nodes",
            "numeric data blood circulation yesno question gini impurity separation cutoff",
            "weight"
          ],
          "questions": null
        },
        "K means clustering": {
          "keywords": [
            "clusters",
            "python",
            "kmeans clustering",
            "euclidean distance initial clusters",
            "means clustering single point",
            "machine learning",
            "data set",
            "means clustering total variation distances samples heat map",
            "variance euclidean distance initial clusters",
            "data points",
            "time",
            "variance",
            "data",
            "centroid",
            "mouse"
          ],
          "questions": null
        },
        "The modelling process": {
          "keywords": [
            "cross validation data",
            "cross validation",
            "iteration best model",
            "linear regression model observations",
            "linear regression model",
            "learn response vector",
            "classification model",
            "machine learning",
            "evaluation metrics reliable estimates",
            "data science tuning parameters",
            "data science",
            "data set",
            "feature selection",
            "root mean squared error",
            "learn response vector classification model",
            "accurate estimate simple code partitions hyper parameters model evaluation trade",
            "best model",
            "higher values",
            "selection scikit",
            "reliable estimates"
          ],
          "questions": null
        }
      },
      "chapter_questions": {
        "keywords": [
          "classification naive bayes",
          "naive bayes",
          "random variables",
          "bayesian methods",
          "initial guess training data",
          "machine learning",
          "total number weight classification",
          "total number weight",
          "bayes rule",
          "finite set",
          "data set",
          "probabilistic model family random variables",
          "prediction naive bayes initial guess training data",
          "dear friend histograms machine learning data",
          "probabilistic model family",
          "dear friend histograms",
          "classification",
          "bayes",
          "prediction",
          "data",
          "support vector machines",
          "vector machines",
          "vector prediction constraint",
          "optimization problem",
          "lagrange multipliers",
          "vector observations misclassifications",
          "green dots outliers",
          "maximum margin",
          "classifier hyperplane soft margin",
          "feature vector",
          "decision boundary",
          "binary classification",
          "vector prediction constraint optimization problem decision",
          "vector machines lagrange multipliers kernel",
          "dimensional space data point weight vector observations misclassifications",
          "dimensional axis channel member polynomial kernel",
          "dual variables",
          "alphas hyperplanes",
          "closest point",
          "statistics",
          "independent variable",
          "linear regression",
          "null hypothesis",
          "test data",
          "average value linear relationship",
          "linear relationship",
          "values software packages average value",
          "null hypothesis squares error term interpretation data",
          "squares error term interpretation data",
          "independent variable average value linear relationship",
          "variation actual values",
          "critical values",
          "positive relationship",
          "value goodness",
          "regressors",
          "correlation",
          "ttest",
          "software",
          "logistic regression",
          "simple linear regression",
          "birth weight data",
          "age weight linearity",
          "logistic function",
          "odds ratio menstrual period predictor slope coefficient logistic regression weight exponential function equation association",
          "value percent vertical axis",
          "observations data",
          "age",
          "weight",
          "linearity",
          "predictions",
          "interpretation",
          "cluster number dendrograms",
          "heat maps sample number similarity clusters",
          "number dendrograms",
          "closest point colors",
          "heat maps sample number similarity",
          "clusters",
          "quest gene manhattan distance square root",
          "decision tree",
          "decision tree heart disease chest pain patient leaf nodes",
          "numeric data blood circulation yesno question gini impurity separation cutoff weight news color choices",
          "news color choices",
          "total number",
          "heart disease chest pain patient leaf nodes",
          "numeric data blood circulation yesno question gini impurity separation cutoff",
          "python",
          "kmeans clustering",
          "euclidean distance initial clusters",
          "means clustering single point",
          "means clustering total variation distances samples heat map",
          "variance euclidean distance initial clusters",
          "data points",
          "time",
          "variance",
          "centroid",
          "mouse",
          "cross validation data",
          "cross validation",
          "iteration best model",
          "linear regression model observations",
          "linear regression model",
          "learn response vector",
          "classification model",
          "evaluation metrics reliable estimates",
          "data science tuning parameters",
          "data science",
          "feature selection",
          "root mean squared error",
          "learn response vector classification model",
          "accurate estimate simple code partitions hyper parameters model evaluation trade",
          "best model",
          "higher values",
          "selection scikit",
          "reliable estimates"
        ],
        "questions": null
      }
    },
    "Machine learning tools in python": {
      "sections": {
        "Keras": {
          "keywords": [
            "softmax",
            "training keras",
            "neural network optimizers",
            "neural network",
            "dense layer data",
            "dense layer",
            "multiclass classification",
            "softmax layer",
            "image accuracy",
            "batch size",
            "data set",
            "test data",
            "class classification softmax test data metrics",
            "classing multi",
            "sequential model",
            "optimizers",
            "size",
            "data",
            "sub",
            "classification"
          ],
          "questions": null
        },
        "Sci-kit Learn": {
          "keywords": [
            "data science",
            "machine learning",
            "markup language",
            "data preparation",
            "programming language",
            "web site",
            "data science anaconda distribution operating systems",
            "anaconda distribution operating systems",
            "scikitlearn",
            "greater"
          ],
          "questions": null
        }
      },
      "chapter_questions": {
        "keywords": [
          "softmax",
          "training keras",
          "neural network optimizers",
          "neural network",
          "dense layer data",
          "dense layer",
          "multiclass classification",
          "softmax layer",
          "image accuracy",
          "batch size",
          "data set",
          "test data",
          "class classification softmax test data metrics",
          "classing multi",
          "sequential model",
          "optimizers",
          "size",
          "data",
          "sub",
          "classification",
          "data science",
          "machine learning",
          "markup language",
          "data preparation",
          "programming language",
          "web site",
          "data science anaconda distribution operating systems",
          "anaconda distribution operating systems",
          "scikitlearn",
          "greater"
        ],
        "questions": null
      }
    },
    "python tools for data analysis": {
      "sections": {
        "Matplotlib": {
          "keywords": [
            "documentation legend sorts",
            "charts plot function numpy second array sake line graph real",
            "legend sorts",
            "world markers axes",
            "documentation",
            "numpy"
          ],
          "questions": null
        },
        "Seaborn": {
          "keywords": [
            "normal distribution",
            "raw data",
            "button histograms promotions",
            "tutorial shapes",
            "wanna axis eggs visitors",
            "revenue data frame line graph"
          ],
          "questions": null
        },
        "Pandas": {
          "keywords": [
            "square brackets data file",
            "data file",
            "data structure",
            "filtering numpy linux python scalar value data structure",
            "filtering numpy linux python scalar value",
            "python",
            "column names",
            "data frame",
            "square brackets",
            "multiple columns",
            "column slicing parenthesis months",
            "numerical value single column average load",
            "pandas",
            "header",
            "filtering",
            "numpy",
            "linux",
            "scalar"
          ],
          "questions": null
        },
        "Numpy": {
          "keywords": [
            "standard deviation",
            "python list metadata random choice exceptions",
            "easiest less space",
            "single line range function",
            "random values",
            "random integers",
            "less memory",
            "python text file",
            "metadata random choice exceptions",
            "square brackets memory address",
            "data",
            "types",
            "floatingpoint",
            "value",
            "numpy",
            "twodimensional",
            "array",
            "standard",
            "deviation",
            "entire"
          ],
          "questions": null
        }
      },
      "chapter_questions": {
        "keywords": [
          "documentation legend sorts",
          "charts plot function numpy second array sake line graph real",
          "legend sorts",
          "world markers axes",
          "documentation",
          "numpy",
          "normal distribution",
          "raw data",
          "button histograms promotions",
          "tutorial shapes",
          "wanna axis eggs visitors",
          "revenue data frame line graph",
          "square brackets data file",
          "data file",
          "data structure",
          "filtering numpy linux python scalar value data structure",
          "filtering numpy linux python scalar value",
          "python",
          "column names",
          "data frame",
          "square brackets",
          "multiple columns",
          "column slicing parenthesis months",
          "numerical value single column average load",
          "pandas",
          "header",
          "filtering",
          "linux",
          "scalar",
          "standard deviation",
          "python list metadata random choice exceptions",
          "easiest less space",
          "single line range function",
          "random values",
          "random integers",
          "less memory",
          "python text file",
          "metadata random choice exceptions",
          "square brackets memory address",
          "data",
          "types",
          "floatingpoint",
          "value",
          "twodimensional",
          "array",
          "standard",
          "deviation",
          "entire"
        ],
        "questions": null
      }
    },
    "natural language processing": {
      "sections": {
        "Parts of speech tagging": {
          "keywords": [
            "conditional probability",
            "noun corpora",
            "joint probability",
            "dynamic programming",
            "tag sequence determiners",
            "data speech",
            "automatic tagging closed class",
            "lexical category tags word classes",
            "pointers",
            "present participle internal structure trigrams",
            "adverbs",
            "training",
            "corpora"
          ],
          "questions": null
        },
        "Sentiment Analysis": {
          "keywords": [],
          "questions": null
        },
        "tokenization": {
          "keywords": [
            "text processing",
            "packard word list",
            "english letters",
            "longest word data",
            "periods sentences",
            "million word hewlett",
            "list",
            "corpus"
          ],
          "questions": null
        },
        "sentiment analysis on tweets using NLTK": {
          "keywords": [
            "sentiment analysis candidates",
            "sentiment analysis",
            "natural language",
            "natural language processing",
            "stop word",
            "data set",
            "moving average",
            "natural language toolkit",
            "data frame subjectivity hashtag timestamp tweets numpy python",
            "secret matplotlib natural language processing technique text blog",
            "processing polarity couple",
            "key dependencies",
            "average punctuation",
            "secret matplotlib",
            "technique text blog",
            "candidates",
            "data frame subjectivity hashtag timestamp tweets",
            "numpy",
            "python",
            "lambda"
          ],
          "questions": null
        },
        "lemmatization and stemming": {
          "keywords": [
            "natural language processing word",
            "natural language processing",
            "edge cases blog posts",
            "python",
            "net limitation python google speech word list edge cases blog posts",
            "stammers",
            "word",
            "net limitation python google speech word",
            "list",
            "stemming",
            "edge"
          ],
          "questions": null
        },
        "text mining": {
          "keywords": [
            "big data",
            "classification domains",
            "online sources",
            "naive bayes",
            "computational linguistics",
            "computer science",
            "natural language processing",
            "topic modeling",
            "big data gender linguistic inquiry researchers",
            "social relations sociology texas topic",
            "computational linguistics radha english webinar literature thematic analysis textual data individual words pilot studies",
            "gender linguistic inquiry researchers",
            "sociology texas topic",
            "large data",
            "topics folks",
            "tips room hour",
            "social",
            "relations",
            "radha english webinar literature thematic analysis textual data individual words pilot studies",
            "author"
          ],
          "questions": null
        }
      },
      "chapter_questions": {
        "keywords": [
          "conditional probability",
          "noun corpora",
          "joint probability",
          "dynamic programming",
          "tag sequence determiners",
          "data speech",
          "automatic tagging closed class",
          "lexical category tags word classes",
          "pointers",
          "present participle internal structure trigrams",
          "adverbs",
          "training",
          "corpora",
          "text processing",
          "packard word list",
          "english letters",
          "longest word data",
          "periods sentences",
          "million word hewlett",
          "list",
          "corpus",
          "sentiment analysis candidates",
          "sentiment analysis",
          "natural language",
          "natural language processing",
          "stop word",
          "data set",
          "moving average",
          "natural language toolkit",
          "data frame subjectivity hashtag timestamp tweets numpy python",
          "secret matplotlib natural language processing technique text blog",
          "processing polarity couple",
          "key dependencies",
          "average punctuation",
          "secret matplotlib",
          "technique text blog",
          "candidates",
          "data frame subjectivity hashtag timestamp tweets",
          "numpy",
          "python",
          "lambda",
          "natural language processing word",
          "edge cases blog posts",
          "net limitation python google speech word list edge cases blog posts",
          "stammers",
          "word",
          "net limitation python google speech word",
          "stemming",
          "edge",
          "big data",
          "classification domains",
          "online sources",
          "naive bayes",
          "computational linguistics",
          "computer science",
          "topic modeling",
          "big data gender linguistic inquiry researchers",
          "social relations sociology texas topic",
          "computational linguistics radha english webinar literature thematic analysis textual data individual words pilot studies",
          "gender linguistic inquiry researchers",
          "sociology texas topic",
          "large data",
          "topics folks",
          "tips room hour",
          "social",
          "relations",
          "radha english webinar literature thematic analysis textual data individual words pilot studies",
          "author"
        ],
        "questions": null
      }
    },
    "types of machine learning": {
      "sections": {
        "semi-supervised learning": {
          "keywords": [
            "trained algorithm classification",
            "clustering algorithms",
            "weight data points",
            "semisupervised predictions",
            "document regression problem",
            "supervised learning",
            "expectationmaximization algorithm",
            "trained algorithm classification clustering algorithms weight data points",
            "gender supervisors",
            "document",
            "regression",
            "problem",
            "algorithm",
            "classification",
            "weight",
            "semisupervised",
            "image",
            "convergence"
          ],
          "questions": null
        },
        "supervised learning": {
          "keywords": [
            "target",
            "prediction learner",
            "algorithm classification input features",
            "supervised learning",
            "decision boundary",
            "machine learning",
            "input features",
            "algorithm",
            "classification",
            "prediction",
            "training",
            "regression"
          ],
          "questions": null
        },
        "unsupervised learning": {
          "keywords": [],
          "questions": null
        },
        "reinforcement learning": {
          "keywords": [
            "current state movements foundations",
            "optimal policy reward functions",
            "agent iteration",
            "reinforcement learning",
            "artificial intelligence",
            "markov decision processes",
            "markov decision",
            "movements foundations",
            "optimal policy reward",
            "output system",
            "system",
            "functions",
            "current",
            "state",
            "outputs",
            "training",
            "inference",
            "agent",
            "iteration"
          ],
          "questions": null
        }
      },
      "chapter_questions": {
        "keywords": [
          "trained algorithm classification",
          "clustering algorithms",
          "weight data points",
          "semisupervised predictions",
          "document regression problem",
          "supervised learning",
          "expectationmaximization algorithm",
          "trained algorithm classification clustering algorithms weight data points",
          "gender supervisors",
          "document",
          "regression",
          "problem",
          "algorithm",
          "classification",
          "weight",
          "semisupervised",
          "image",
          "convergence",
          "target",
          "prediction learner",
          "algorithm classification input features",
          "decision boundary",
          "machine learning",
          "input features",
          "prediction",
          "training",
          "current state movements foundations",
          "optimal policy reward functions",
          "agent iteration",
          "reinforcement learning",
          "artificial intelligence",
          "markov decision processes",
          "markov decision",
          "movements foundations",
          "optimal policy reward",
          "output system",
          "system",
          "functions",
          "current",
          "state",
          "outputs",
          "inference",
          "agent",
          "iteration"
        ],
        "questions": null
      }
    },
    "The data science process": {
      "sections": {
        "data preparation": {
          "keywords": [
            "domain knowledge categorical variables",
            "domain knowledge",
            "categorical variables",
            "predictive model",
            "data dictionary",
            "data cleaning",
            "predictive model missing value multiple sources duplications corruption merging predictions",
            "missing value multiple sources duplications corruption merging predictions",
            "dummy variable",
            "million records",
            "analysts data sources",
            "data",
            "merging",
            "interactive",
            "visualization"
          ],
          "questions": null
        },
        "defining research goals and creating a project charter": {
          "keywords": [
            "quality assurance",
            "ios",
            "smaller project final design bottom line cheat sheet quality assurance",
            "business case",
            "expectations leadership opportunity deadlines",
            "key stakeholders boundaries authority deliverables meetings project success site deployment business analyst",
            "software",
            "moment",
            "smaller project final design bottom line cheat sheet"
          ],
          "questions": null
        },
        "Exploratory Data analysis": {
          "keywords": [
            "interquartile range",
            "chart outliers",
            "median exploratory data analysis",
            "exploratory data analysis",
            "categorical variables",
            "data file",
            "data analysis",
            "statistical methods",
            "standard deviation",
            "categorical data",
            "data entry",
            "range standard deviation maximum value",
            "correlation second place bimodal distribution statistical methods",
            "correlation second place bimodal distribution",
            "box plot",
            "data types",
            "continuous data session test",
            "choices tabular form descriptive",
            "median",
            "interval"
          ],
          "questions": null
        },
        "Facets of Data": {
          "keywords": [
            "unstructured data",
            "artificial intelligence",
            "relational database",
            "excel spreadsheet",
            "unstructured data artificial intelligence open",
            "ended question dimension datasets bernard relational database",
            "open",
            "spreadsheet"
          ],
          "questions": null
        },
        "model building": {
          "keywords": [
            "regressor full search degrees",
            "model validation",
            "interaction terms",
            "full model",
            "degrees of freedom",
            "data set",
            "search degrees",
            "predictions data",
            "value significance level",
            "regressor",
            "full",
            "freedom",
            "coefficient model terms data points",
            "noise",
            "interaction",
            "value"
          ],
          "questions": null
        },
        "Data Collection": {
          "keywords": [
            "training data",
            "training",
            "data garbage",
            "deep learning",
            "models image training",
            "data collection",
            "machine learning",
            "standard deviation",
            "algorithm deep learning models image training",
            "input variables",
            "underrepresented classes",
            "variance",
            "algorithm",
            "garbage",
            "image",
            "scaling"
          ],
          "questions": null
        }
      },
      "chapter_questions": {
        "keywords": [
          "domain knowledge categorical variables",
          "domain knowledge",
          "categorical variables",
          "predictive model",
          "data dictionary",
          "data cleaning",
          "predictive model missing value multiple sources duplications corruption merging predictions",
          "missing value multiple sources duplications corruption merging predictions",
          "dummy variable",
          "million records",
          "analysts data sources",
          "data",
          "merging",
          "interactive",
          "visualization",
          "quality assurance",
          "ios",
          "smaller project final design bottom line cheat sheet quality assurance",
          "business case",
          "expectations leadership opportunity deadlines",
          "key stakeholders boundaries authority deliverables meetings project success site deployment business analyst",
          "software",
          "moment",
          "smaller project final design bottom line cheat sheet",
          "interquartile range",
          "chart outliers",
          "median exploratory data analysis",
          "exploratory data analysis",
          "data file",
          "data analysis",
          "statistical methods",
          "standard deviation",
          "categorical data",
          "data entry",
          "range standard deviation maximum value",
          "correlation second place bimodal distribution statistical methods",
          "correlation second place bimodal distribution",
          "box plot",
          "data types",
          "continuous data session test",
          "choices tabular form descriptive",
          "median",
          "interval",
          "unstructured data",
          "artificial intelligence",
          "relational database",
          "excel spreadsheet",
          "unstructured data artificial intelligence open",
          "ended question dimension datasets bernard relational database",
          "open",
          "spreadsheet",
          "regressor full search degrees",
          "model validation",
          "interaction terms",
          "full model",
          "degrees of freedom",
          "data set",
          "search degrees",
          "predictions data",
          "value significance level",
          "regressor",
          "full",
          "freedom",
          "coefficient model terms data points",
          "noise",
          "interaction",
          "value",
          "training data",
          "training",
          "data garbage",
          "deep learning",
          "models image training",
          "data collection",
          "machine learning",
          "algorithm deep learning models image training",
          "input variables",
          "underrepresented classes",
          "variance",
          "algorithm",
          "garbage",
          "image",
          "scaling"
        ],
        "questions": null
      }
    }
  }
}